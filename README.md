# Spotify MCP History Collector

A containerized system that enables ChatGPT-style assistants to analyze Spotify listening patterns by collecting playback history over time and exposing it via an MCP-compatible tool interface.

## Architecture

| Service                       | Description                                           | Port |
|-------------------------------|-------------------------------------------------------|------|
| **api** (FastAPI)             | Spotify OAuth, MCP tool endpoints, admin APIs         | 8000 |
| **collector** (Python worker) | Polls Spotify API, ingests ZIP exports, stores plays  | --   |
| **frontend** (FastAPI)        | Management UI for users, sync status, analytics, logs | 8001 |
| **postgres**                  | PostgreSQL 16 data storage                            | 5432 |

## Prerequisites

- [Conda](https://docs.conda.io/en/latest/miniconda.html) (recommended) **or** Python 3.14+ with venv
- [Docker](https://docs.docker.com/get-docker/) and Docker Compose (for running services)
- [Git](https://git-scm.com/)
- (Windows) `make` via [Git Bash](https://gitforwindows.org/), [WSL](https://learn.microsoft.com/en-us/windows/wsl/), or [Chocolatey](https://chocolatey.org/) (`choco install make`) -- or run the commands from the Makefile manually

## Development Setup

### 1. Clone and configure environment variables

```bash
git clone <repo-url>
cd spotify-mcp-history-collector
cp .env.example .env
```

Edit `.env` and fill in:
- `SPOTIFY_CLIENT_ID` / `SPOTIFY_CLIENT_SECRET` -- from the [Spotify Developer Dashboard](https://developer.spotify.com/dashboard)
- `TOKEN_ENCRYPTION_KEY` -- generate with `python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"`
- `ADMIN_TOKEN` -- any secret string for admin API auth

### 2. Create the Python environment

**With conda (recommended):**

```bash
conda env create -f environment.yml
conda activate spotify-mcp
pre-commit install
```

`environment.yml` installs all four packages (`shared`, `api`, `collector`, `frontend`) as **editable installs** with dev dependencies. This means pip reads each package's `pyproject.toml`, resolves the full dependency tree, and installs everything -- no separate `pip install -r requirements.txt` step needed. The `requirements.txt` files (generated by pip-compile) are only used by Docker for reproducible, pinned builds.

**Without conda (venv):**

```bash
python -m venv .venv

# Linux/macOS
source .venv/bin/activate

# Windows
.venv\Scripts\activate

make setup
```

`make setup` installs pip-tools, pre-commit, all four packages in editable mode with dev extras, and activates the pre-commit hooks.

### 3. Verify the environment

```bash
# All 11 models should register
python -c "from shared.db import Base; print(len(Base.metadata.tables), 'tables')"

# Lint should pass
make lint

# Type checking
make typecheck
```

## Running Services

### With Docker (full stack)

```bash
# Start everything (builds images on first run)
make docker-up
# or: docker-compose up --build -d

# View logs
docker-compose logs -f api
docker-compose logs -f collector

# Stop
make docker-down
# or: docker-compose down
```

Services start in dependency order: postgres (waits for healthy) -> api (waits for healthy) -> collector, frontend.

### Run database migrations

Migrations run inside the API container (or locally if Postgres is reachable):

```bash
# Inside container
docker-compose exec api alembic upgrade head

# Locally (requires DATABASE_URL in env or .env)
cd services/api
alembic upgrade head
```

### Create a new migration

```bash
cd services/api
alembic revision --autogenerate -m "description of change"
```

### Run a single service locally (outside Docker)

Useful for debugging with an IDE. Start Postgres via Docker, then run the service directly:

```bash
# Start only Postgres
docker-compose up -d postgres

# Run API locally
cd services/api
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Run collector locally
cd services/collector
python -m collector.main

# Run frontend locally
cd services/frontend
uvicorn frontend.main:app --host 0.0.0.0 --port 8001 --reload
```

## Code Quality

### Linting and formatting (ruff)

```bash
make lint          # check only
make format        # auto-fix + reformat
```

### Type checking (mypy)

```bash
make typecheck
```

### Testing (pytest)

```bash
make test          # run all tests
make test-cov      # run with HTML coverage report
```

<!-- TODO: Add instructions for running tests against a test database once test fixtures are implemented -->

### Pre-commit hooks

Installed during setup. On every `git commit`, the following run automatically:
- **ruff** -- lint check with auto-fix + format
- **mypy** -- type checking across all source directories

To run manually: `pre-commit run --all-files`

## Dependency Management

Dependencies are defined in each package's `pyproject.toml` (source of truth). Pinned `requirements.txt` files are generated by [pip-tools](https://pip-tools.readthedocs.io/) for reproducible Docker builds.

```bash
# Regenerate pinned requirements from pyproject.toml
make compile-deps

# Upgrade all pins to latest allowed versions
make upgrade-deps
```

After running either command, commit the updated `requirements.txt` / `requirements-dev.txt` files.

## Project Structure

```
services/
├── shared/                    # Shared database package (used by api + collector)
│   ├── pyproject.toml
│   └── src/shared/
│       ├── config/            # DatabaseSettings, constants
│       └── db/                # Base, enums, DatabaseManager, models/
├── api/                       # spotify-mcp-api (FastAPI)
│   ├── Dockerfile
│   ├── alembic/               # Database migrations
│   └── src/app/
│       ├── dependencies.py    # DatabaseManager instance
│       ├── main.py            # FastAPI app + lifespan
│       ├── auth/              # Spotify OAuth flow
│       ├── mcp/               # MCP tool catalog + dispatcher
│       ├── admin/             # Admin API endpoints
│       ├── history/           # History queries + analysis
│       ├── spotify/           # Typed Spotify client wrapper
│       └── db/                # Re-exports from shared
├── collector/                 # spotify-history-collector (worker)
│   ├── Dockerfile
│   └── src/collector/
│       └── main.py            # Entry point (runloop placeholder)
└── frontend/                  # admin-frontend (FastAPI + Jinja2)
    ├── Dockerfile
    └── src/frontend/
        └── main.py            # FastAPI app
```

## Health Checks

```bash
curl http://localhost:8000/healthz   # API
curl http://localhost:8001/healthz   # Frontend
```

## License

See [LICENSE](LICENSE).
